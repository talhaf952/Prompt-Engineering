
1st Lecture:
We'll learn some prompting best practices for software development, then we'll cover some common use cases, summarizing, inferring, transforming, expanding, and then we'll build a chatbot 
using an LLM. We hope that this will spark our imagination about new applications that you can build. So in the development of large language models or LLMs, there have been broadly two types of LLMs.
1. Base LLMs
2. instruction-tuned LLMs. 
So, base LLM has been trained to predict the next word based on text training data, often trained on a large amount of data from the internet and other sources to figure out what's the next most likely word to follow. So, for example, if you were to prompt us once upon a time there was a unicorn, it may complete this, that is it may predict the next several words are that live in a magical forest with all unicorn friends. But if you were to prompt us with what is the capital of France, then based on what articles on the internet might have, it's quite possible that the base LLM will complete this with what is France's largest city, what is France's population and so on, because articles on the internet could quite plausibly be lists of quiz questions about the country of France.
In contrast, an instruction-tuned LLM, which is where a lot of momentum of LLM research and practice has been going, an instruction-tuned LLM has been trained to follow instructions.
